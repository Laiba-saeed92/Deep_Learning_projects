{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laiba-saeed92/Deep_Learning_projects/blob/main/CNN_model_and_optimization_using_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWuffCi-krvO",
        "outputId": "70c266ab-74eb-4c20-eda6-55137f579983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sretiVs1oWHB",
        "outputId": "0723abe6-5e81-47c8-a10f-64abd49a44f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WZIdIVfop5E",
        "outputId": "311141df-c7b2-4a7f-e7e0-24890481e248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels)= fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-82g9-PHu3-J"
      },
      "outputs": [],
      "source": [
        "train_images= train_images/255.0 #Normalizing is a form of scaling, specifically used when working with image data, especially in Convolutional Neural Networks (CNNs) or other image-based models.\n",
        "test_images= test_images/255.0 #Image pixel values are typically integers from 0 to 255.Dividing by 255.0 normalizes these values to the range [0.0, 1.0].\n",
        "#ANN works with numerical/tabular data so standardcaler is used but for CNN normalization is used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtmZfB_XvYK6",
        "outputId": "1c5a860e-5146-4768-b826-1826ecba62ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "60000\n",
            "10000\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(train_images[0].shape)\n",
        "print(len(train_images))\n",
        "print(len(test_images))\n",
        "print(type(train_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-1sI77svetV"
      },
      "outputs": [],
      "source": [
        "#CNNs expect 4D input with shape:\n",
        "#[Number of Images, Height, Width, Channels] If your images are grayscale, you need to add that extra dimension (1 channel).\n",
        "#This reshape ensures that the data has the correct shape for convolution operations.\n",
        "train_images= train_images.reshape(len(train_images),28,28,1)\n",
        "test_images= test_images.reshape(len(test_images),28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjR7Zu-I7IwT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd8SLqfa8LMX"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "  model= Sequential()\n",
        "  model.add(Input(shape=(28, 28, 1)))\n",
        "  model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16), kernel_size=hp.Choice( 'conv_1_kernel', values=[3,5]),activation='relu')), #kerenel_size is filter size(how big) and conv_1_filter is range of filter used btw 32 to 128 with step of 16 e.g(32, 48,...128)\n",
        "  model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16), kernel_size=hp.Choice( 'conv_2_kernel', values=[3,5]),activation='relu')),\n",
        "  model.add(Flatten()),\n",
        "  model.add(Dense(units=hp.Int('dense_1_unit', min_value=16, max_value=32, step=16), activation='relu')),\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning rate', [1e-1, 1e-2, 1e-3])), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwj4a2EuA0I_"
      },
      "outputs": [],
      "source": [
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciqtJSL2B4BD"
      },
      "outputs": [],
      "source": [
        "tuner_search=RandomSearch(build_model, objective='val_accuracy', max_trials=5, directory='output', project_name='fashion mnist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO-1vg62F3Fm",
        "outputId": "246696b7-2c6f-48f7-b148-bc44c6616d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 24m 25s]\n",
            "val_accuracy: 0.8690000176429749\n",
            "\n",
            "Best val_accuracy So Far: 0.9073333144187927\n",
            "Total elapsed time: 00h 52m 30s\n",
            "\n",
            "Search: Running Trial #4\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "32                |128               |conv_1_filter\n",
            "5                 |3                 |conv_1_kernel\n",
            "64                |32                |conv_2_filter\n",
            "5                 |3                 |conv_2_kernel\n",
            "16                |16                |dense_1_unit\n",
            "0.001             |0.001             |learning rate\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 125ms/step - accuracy: 0.7444 - loss: 0.7222 - val_accuracy: 0.8677 - val_loss: 0.3605\n",
            "Epoch 2/3\n",
            "\u001b[1m1574/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - accuracy: 0.8856 - loss: 0.3231"
          ]
        }
      ],
      "source": [
        "tuner_search.search(train_images, train_labels, epochs=3, validation_split=0.1) #Search() for the best hyperparameters by trying many models internally (each one using model.fit() inside)\n",
        "#validation_slit=0.2 this only works if X_train and y_train are array-like (e.g., NumPy arrays, not tf.data.Dataset)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzOM-F1RCSAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLRC7CC16k8eC/OMe+DH7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}